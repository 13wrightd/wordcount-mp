Daniel Wright and Evan Gutman	

diw5233@psu.edu
elg5195@psu.edu

(i) Group member names
Daniel Wright
Evan Gutman

(ii) Program description
The program first loads the input file and seeks to the end, then uses the ftell command to tell the size of the file.
this gets stored in a variable called sz and then divided by n (number of processes). The program then goes to the sz/n'th bit of the file and 
then seeks to the next newline or space character. This point is saved to a variable endpoint which will later signal when that process
should stop. The endpoint is used as the startpoint for the next process and the process repeats. So startpoint and endpoint are constantly 
getting updated for each process but before they get changed, the program forks so that the child process will still have those points. 
each child process then uses the algorithm from the first project to make a linked list, which then gets piped through 1 of the N pipes
to the parent where the parent merges it with its own linked list, which consists of the first sz/n bits.

(iii) Difficulties
We mostly had difficulties learning the fork command and with piping.
forking was straight forward once we looked up some examples and understood what they meant. We thought that because pointers point to an area of 
data, that our linked list could be accessed from all forked processes but we learned that a forked process has a copy of the parents memory 
space so the pointers would be copied but they would now point to seperate copies. We also had some issues with piping. We knew how to use 1 pipe
and have all child processes use it, but the guidelines said to use n-1 pipes. This took a bit of time to come up with a solution but we ended up
using a dynamically allocated multidimensional array, dynamic because N can change. 

(iv) System calls and library functions used
stdio.h, stdlib.h, stdbool.h, sys/types.h, string.h, time.h, ctype.h, were the different libraries used.
Some functions and system calls we used were pipe, fork, timing functions, fopen, fgetc, ftell, fseek, and wait.

(v) Interesting design choices
The choice design to pipe all the data to the parent was in our opinion an interesting choice. From research, we knew it was possible to have some 
shared memory between the processes. This would make it possible for each process to add their data directly the final linked list rather than 
making their own, and then piping the information. Doing it this way would be a lot easier to program and also be more efficient but doing it the 
way described in the guidelines allowed us to learn how pipes work.

(vi) Performance measurement results
wordcount.c
		a. Pangur Ban
			Mean Runtime = 0.000530s
			Standard Deviation = .000270s
		b. Hamlet
			Mean Runtime = 0.784230s
			Standard Deviation = 0.033310s
		c. Arabian Nights
			Mean Runtime = 31.617030s
			Standard Deviation = 1.736050s
	wordcount.sh
		a. Pangur Ban
			Mean Runtime = 0.023960s
			Standard Deviation = 0.069950s
		b. Hamlet
			Mean Runtime = 0.089090s
			Standard Deviation = 0.016780s
		c. Arabian Nights
			Mean Runtime = 0.837650s
			Standard Deviation = 0.022480s